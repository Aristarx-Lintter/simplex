{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x113c3d810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "plot_mse_comparison_experiment_dashboard.py\n",
    "\n",
    "This script scans the local \"analysis_cache\" folder for experiments (runs) that contain a\n",
    "'run_data.csv' file (produced by your analysis script). It then launches an interactive\n",
    "dashboard (using Dash) that lets you select an experiment and filter the data via checkboxes for:\n",
    "\n",
    "  - Analysis Type: Trained, Trained Shuffled, and Random.\n",
    "  - Belief Type: Normalized and Unnormalized.\n",
    "  - Layer Selection: Individual layers (with the highest index shown as \"All Layers (Concat)\").\n",
    "\n",
    "For trained models the x axis shows the checkpoint number; for random controls the data are \n",
    "averaged over seeds and displayed as a horizontal line with a shaded region representing the SEM.\n",
    "\n",
    "Usage:\n",
    "    python plot_mse_comparison_experiment_dashboard.py\n",
    "\n",
    "Dependencies:\n",
    "    - dash\n",
    "    - pandas\n",
    "    - plotly\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Scan for Experiments (Runs)\n",
    "# ------------------------------\n",
    "\n",
    "BASE_DIR = Path(\"analysis_cache\")\n",
    "experiment_csvs = list(BASE_DIR.glob(\"**/run_data.csv\"))\n",
    "experiment_options = []\n",
    "for csv_file in experiment_csvs:\n",
    "    parts = csv_file.parts\n",
    "    # Expected structure: analysis_cache/<sweep_id>/<run_id>/run_data.csv\n",
    "    if len(parts) >= 4:\n",
    "        sweep_id = parts[-3]\n",
    "        run_id = parts[-2]\n",
    "        label = f\"Sweep {sweep_id} | Run {run_id}\"\n",
    "        value = str(csv_file)\n",
    "        experiment_options.append({'label': label, 'value': value})\n",
    "\n",
    "experiment_options = sorted(experiment_options, key=lambda x: x['label'])\n",
    "default_experiment = experiment_options[0]['value'] if experiment_options else None\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Define Checkbox Options\n",
    "# ------------------------------\n",
    "\n",
    "analysis_type_options = [\n",
    "    {'label': 'Trained', 'value': 'trained'},\n",
    "    {'label': 'Trained Shuffled', 'value': 'trained_shuffled'},\n",
    "    {'label': 'Random', 'value': 'random'}\n",
    "]\n",
    "\n",
    "belief_type_options = [\n",
    "    {'label': 'Normalized', 'value': 'normalized'},\n",
    "    {'label': 'Unnormalized', 'value': 'unnormalized'}\n",
    "]\n",
    "\n",
    "# To initialize the layer checklist, we load the default experiment CSV.\n",
    "if default_experiment is not None:\n",
    "    try:\n",
    "        df_default = pd.read_csv(default_experiment)\n",
    "        def compute_x_value(row):\n",
    "            if row['random_or_trained'] == 'random':\n",
    "                return row['seed']\n",
    "            else:\n",
    "                try:\n",
    "                    return float(row['checkpoint'])\n",
    "                except:\n",
    "                    return None\n",
    "        df_default['x_value'] = df_default.apply(compute_x_value, axis=1)\n",
    "        layers_default = sorted(df_default['layer_index'].unique())\n",
    "    except Exception as e:\n",
    "        print(\"Error reading default experiment CSV:\", e)\n",
    "        layers_default = []\n",
    "else:\n",
    "    layers_default = []\n",
    "\n",
    "max_layer = max(layers_default) if layers_default else None\n",
    "layer_options = []\n",
    "for l in layers_default:\n",
    "    label = f\"Layer {int(l)}\" if l != max_layer else \"All Layers (Concat)\"\n",
    "    layer_options.append({'label': label, 'value': l})\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Build the Dash App Layout\n",
    "# ------------------------------\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"MSE Comparison Dashboard\"\n",
    "\n",
    "app.layout = html.Div(\n",
    "    style={'fontFamily': 'Arial, sans-serif', 'margin': '20px'},\n",
    "    children=[\n",
    "        html.H1(\"MSE Comparison Dashboard\", style={'textAlign': 'center'}),\n",
    "        html.Div([\n",
    "            html.Label(\"Select Experiment:\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"experiment-dropdown\",\n",
    "                options=experiment_options,\n",
    "                value=default_experiment,\n",
    "                clearable=False,\n",
    "                style={\"width\": \"80%\", \"margin\": \"auto\"}\n",
    "            )\n",
    "        ], style={'margin-bottom': '20px'}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H3(\"Analysis Type\"),\n",
    "                dcc.Checklist(\n",
    "                    id='analysis-type-checklist',\n",
    "                    options=analysis_type_options,\n",
    "                    value=['trained', 'trained_shuffled', 'random'],\n",
    "                    labelStyle={'display': 'inline-block', 'margin-right': '15px'}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc', 'margin-right': '20px'}),\n",
    "            html.Div([\n",
    "                html.H3(\"Belief Type\"),\n",
    "                dcc.Checklist(\n",
    "                    id='belief-type-checklist',\n",
    "                    options=belief_type_options,\n",
    "                    value=['normalized', 'unnormalized'],\n",
    "                    labelStyle={'display': 'inline-block', 'margin-right': '15px'}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc', 'margin-right': '20px'}),\n",
    "            html.Div([\n",
    "                html.H3(\"Layer Selection\"),\n",
    "                dcc.Checklist(\n",
    "                    id='layer-checklist',\n",
    "                    options=layer_options,\n",
    "                    value=layers_default,\n",
    "                    labelStyle={'display': 'inline-block', 'margin-right': '15px'}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc'})\n",
    "        ], style={'display': 'flex', 'justifyContent': 'center', 'margin-bottom': '20px'}),\n",
    "        dcc.Graph(id='mse-graph')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Callbacks\n",
    "# ------------------------------\n",
    "\n",
    "@app.callback(\n",
    "    Output('layer-checklist', 'options'),\n",
    "    Output('layer-checklist', 'value'),\n",
    "    Input('experiment-dropdown', 'value')\n",
    ")\n",
    "def update_layer_options(selected_experiment):\n",
    "    if not selected_experiment:\n",
    "        return [], []\n",
    "    try:\n",
    "        df_exp = pd.read_csv(selected_experiment)\n",
    "        def compute_x_value(row):\n",
    "            if row['random_or_trained'] == 'random':\n",
    "                return row['seed']\n",
    "            else:\n",
    "                try:\n",
    "                    return float(row['checkpoint'])\n",
    "                except:\n",
    "                    return None\n",
    "        df_exp['x_value'] = df_exp.apply(compute_x_value, axis=1)\n",
    "        layers_exp = sorted(df_exp['layer_index'].unique())\n",
    "        if not layers_exp:\n",
    "            return [], []\n",
    "        max_layer_exp = max(layers_exp)\n",
    "        opts = [{'label': f\"Layer {int(l)}\" if l != max_layer_exp else \"All Layers (Concat)\", 'value': l} for l in layers_exp]\n",
    "        return opts, layers_exp\n",
    "    except Exception as e:\n",
    "        print(\"Error updating layer options:\", e)\n",
    "        return [], []\n",
    "\n",
    "@app.callback(\n",
    "    Output('mse-graph', 'figure'),\n",
    "    Input('experiment-dropdown', 'value'),\n",
    "    Input('analysis-type-checklist', 'value'),\n",
    "    Input('belief-type-checklist', 'value'),\n",
    "    Input('layer-checklist', 'value')\n",
    ")\n",
    "def update_graph(selected_experiment, selected_analysis_types, selected_belief_types, selected_layers):\n",
    "    if not selected_experiment or not selected_analysis_types or not selected_belief_types or not selected_layers:\n",
    "        return go.Figure()\n",
    "    try:\n",
    "        df_exp = pd.read_csv(selected_experiment)\n",
    "    except Exception as e:\n",
    "        print(\"Error reading CSV:\", e)\n",
    "        return go.Figure()\n",
    "    \n",
    "    # Compute x_value: for random controls, use seed; else, use checkpoint (as float).\n",
    "    def compute_x_value(row):\n",
    "        if row['random_or_trained'] == 'random':\n",
    "            return row['seed']\n",
    "        else:\n",
    "            try:\n",
    "                return float(row['checkpoint'])\n",
    "            except:\n",
    "                return None\n",
    "    df_exp['x_value'] = df_exp.apply(compute_x_value, axis=1)\n",
    "    \n",
    "    # Filter based on selections.\n",
    "    filtered = df_exp[\n",
    "        df_exp['random_or_trained'].isin(selected_analysis_types) &\n",
    "        df_exp['norm_type'].isin(selected_belief_types) &\n",
    "        df_exp['layer_index'].isin(selected_layers)\n",
    "    ]\n",
    "    filtered = filtered.sort_values('x_value')\n",
    "    \n",
    "    # Determine x-axis range from non-random data.\n",
    "    non_random = filtered[filtered['random_or_trained'] != 'random']\n",
    "    if not non_random.empty:\n",
    "        x_min = non_random['x_value'].min()\n",
    "        x_max = non_random['x_value'].max()\n",
    "    else:\n",
    "        x_min = filtered['x_value'].min()\n",
    "        x_max = filtered['x_value'].max()\n",
    "    x_range = (x_min, x_max)\n",
    "    \n",
    "    # For color mapping, use all layers from the full dataset (df_exp), so that the mapping stays constant.\n",
    "    all_layers = sorted(df_exp['layer_index'].unique())\n",
    "    if not all_layers:\n",
    "        return go.Figure()  # Return empty figure if no layers\n",
    "        \n",
    "    max_layer_val = max(all_layers)\n",
    "    # Identify non-concat layers (all except the maximum)\n",
    "    non_concat_layers = [l for l in all_layers if l != max_layer_val]\n",
    "    \n",
    "    color_map = {}\n",
    "    for layer in all_layers:\n",
    "        if layer == max_layer_val:\n",
    "            color_map[layer] = 'black'\n",
    "        else:\n",
    "            # Handle the case where there's only one non-concat layer\n",
    "            if len(non_concat_layers) == 1:\n",
    "                frac = 0.5  # Use middle of colorscale for single layer\n",
    "            else:\n",
    "                # Normalize between 0 and 1 based on position in non_concat_layers\n",
    "                frac = non_concat_layers.index(layer) / (len(non_concat_layers) - 1) if len(non_concat_layers) > 1 else 0\n",
    "            sampled = px.colors.sample_colorscale(\"Oryel\", frac)\n",
    "            color_map[layer] = sampled[0]\n",
    "    \n",
    "    # Define line dash styles for each analysis type.\n",
    "    line_styles = {\n",
    "        'trained': 'solid',\n",
    "        'trained_shuffled': 'dash',\n",
    "        'random': 'dot'\n",
    "    }\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    # Group by analysis type, belief type, and layer_index.\n",
    "    grouped = filtered.groupby(['random_or_trained', 'norm_type', 'layer_index'])\n",
    "    for (analysis_type, norm_type, layer_index), group in grouped:\n",
    "        layer_label = f\"Layer {int(layer_index)}\" if layer_index != max_layer_val else \"All Layers (Concat)\"\n",
    "        trace_label = f\"{analysis_type.title()} | {norm_type.title()} | {layer_label}\"\n",
    "        trace_color = color_map.get(layer_index, \"black\")\n",
    "        \n",
    "        if analysis_type == 'random':\n",
    "            # Aggregate over seeds.\n",
    "            avg_MSE = group['MSE'].mean()\n",
    "            std_MSE = group['MSE'].std()\n",
    "            n = group.shape[0]\n",
    "            sem_MSE = std_MSE / math.sqrt(n) if n > 0 else 0\n",
    "            # Plot a shaded region for (avg Â± SEM) across the x_range.\n",
    "            x_shaded = [x_range[0], x_range[1], x_range[1], x_range[0]]\n",
    "            y_shaded = [avg_MSE - sem_MSE, avg_MSE - sem_MSE, avg_MSE + sem_MSE, avg_MSE + sem_MSE]\n",
    "            # Convert the hex color to an RGBA with transparency.\n",
    "            # This simple conversion assumes hex color in format \"#RRGGBB\".\n",
    "            try:\n",
    "                r = int(trace_color[1:3], 16)\n",
    "                g = int(trace_color[3:5], 16)\n",
    "                b = int(trace_color[5:7], 16)\n",
    "                fill_color = f\"rgba({r},{g},{b},0.2)\"\n",
    "            except:\n",
    "                fill_color = \"rgba(0,0,0,0.2)\"\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_shaded,\n",
    "                y=y_shaded,\n",
    "                fill=\"toself\",\n",
    "                fillcolor=fill_color,\n",
    "                line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                showlegend=False,\n",
    "                hoverinfo='skip'\n",
    "            ))\n",
    "            # Plot the horizontal mean line.\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[x_range[0], x_range[1]],\n",
    "                y=[avg_MSE, avg_MSE],\n",
    "                mode='lines',\n",
    "                name=trace_label,\n",
    "                line=dict(color=trace_color, dash=line_styles[analysis_type], width=3),\n",
    "                hovertemplate=(\n",
    "                    f\"Analysis Type: {analysis_type}<br>\" +\n",
    "                    f\"Belief Type: {norm_type}<br>\" +\n",
    "                    f\"{layer_label}<br>\" +\n",
    "                    f\"Avg MSE: {avg_MSE:.5f}<br>\" +\n",
    "                    f\"SEM: {sem_MSE:.5f}<extra></extra>\"\n",
    "                )\n",
    "            ))\n",
    "        else:\n",
    "            group = group.sort_values('x_value')\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=group['x_value'],\n",
    "                y=group['MSE'],\n",
    "                mode='lines+markers',\n",
    "                name=trace_label,\n",
    "                line=dict(color=trace_color, dash=line_styles[analysis_type]),\n",
    "                marker=dict(symbol='circle', size=5),  # Reduced marker size.\n",
    "                hovertemplate=(\n",
    "                    f\"Analysis Type: {analysis_type}<br>\" +\n",
    "                    f\"Belief Type: {norm_type}<br>\" +\n",
    "                    f\"{layer_label}<br>\" +\n",
    "                    \"X: %{x}<br>\" +\n",
    "                    \"MSE: %{y:.5f}<extra></extra>\"\n",
    "                )\n",
    "            ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"MSE vs. Checkpoint/Seed (Unified Comparison)\",\n",
    "        xaxis_title=\"Checkpoint Number (for Trained) or Seed (Random controls averaged)\",\n",
    "        yaxis_title=\"MSE (log scale)\",\n",
    "        yaxis_type=\"log\",\n",
    "        legend_title=\"Trace Groups\",\n",
    "        margin={'l': 50, 'r': 50, 't': 50, 'b': 50}\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Run the App\n",
    "# ------------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13a01a9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "plot_mse_comparison_normalized_dashboard.py\n",
    "\n",
    "This script scans the local \"analysis_cache\" folder for experiments (runs)\n",
    "that contain a 'run_data.csv' file. It then launches an interactive dashboard\n",
    "(using Dash) that lets you select an experiment and filter the data via checkboxes for:\n",
    "\n",
    "  - Analysis Type: Trained, Trained Shuffled, and Random.\n",
    "  - Belief Type: Normalized and Unnormalized.\n",
    "  - Layer Selection: Individual layers (with the highest index shown as \"All Layers (Concat)\").\n",
    "\n",
    "Additionally, two new dropdowns allow you to choose:\n",
    "  - Which shuffled baseline to use for normalization (\"Trained Shuffled\" vs. \"Random\").\n",
    "  - Which normalization method to apply (None, Ratio, Percent Difference, or Z-Score).\n",
    "\n",
    "For trained models the x axis shows the checkpoint number; for random controls the\n",
    "data are averaged over seeds (or used in aggregate) and displayed accordingly.\n",
    "\n",
    "Usage:\n",
    "    python plot_mse_comparison_normalized_dashboard.py\n",
    "\n",
    "Dependencies:\n",
    "    - dash\n",
    "    - pandas\n",
    "    - plotly\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Scan for Experiments (Runs)\n",
    "# ------------------------------\n",
    "\n",
    "BASE_DIR = Path(\"analysis_cache\")\n",
    "experiment_csvs = list(BASE_DIR.glob(\"**/run_data.csv\"))\n",
    "experiment_options = []\n",
    "for csv_file in experiment_csvs:\n",
    "    parts = csv_file.parts\n",
    "    # Expected structure: analysis_cache/<sweep_id>/<run_id>/run_data.csv\n",
    "    if len(parts) >= 4:\n",
    "        sweep_id = parts[-3]\n",
    "        run_id = parts[-2]\n",
    "        label = f\"Sweep {sweep_id} | Run {run_id}\"\n",
    "        value = str(csv_file)\n",
    "        experiment_options.append({'label': label, 'value': value})\n",
    "\n",
    "experiment_options = sorted(experiment_options, key=lambda x: x['label'])\n",
    "default_experiment = experiment_options[0]['value'] if experiment_options else None\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Define Filter Options\n",
    "# ------------------------------\n",
    "\n",
    "analysis_type_options = [\n",
    "    {'label': 'Trained', 'value': 'trained'},\n",
    "    {'label': 'Trained Shuffled', 'value': 'trained_shuffled'},\n",
    "    {'label': 'Random', 'value': 'random'}\n",
    "]\n",
    "\n",
    "belief_type_options = [\n",
    "    {'label': 'Normalized', 'value': 'normalized'},\n",
    "    {'label': 'Unnormalized', 'value': 'unnormalized'}\n",
    "]\n",
    "\n",
    "# Load the default experiment CSV to initialize the layer checklist.\n",
    "if default_experiment is not None:\n",
    "    try:\n",
    "        df_default = pd.read_csv(default_experiment)\n",
    "        def compute_x_value(row):\n",
    "            if row['random_or_trained'] == 'random':\n",
    "                return row['seed']\n",
    "            else:\n",
    "                try:\n",
    "                    return float(row['checkpoint'])\n",
    "                except:\n",
    "                    return None\n",
    "        df_default['x_value'] = df_default.apply(compute_x_value, axis=1)\n",
    "        layers_default = sorted(df_default['layer_index'].unique())\n",
    "    except Exception as e:\n",
    "        print(\"Error reading default experiment CSV:\", e)\n",
    "        layers_default = []\n",
    "else:\n",
    "    layers_default = []\n",
    "\n",
    "max_layer = max(layers_default) if layers_default else None\n",
    "layer_options = []\n",
    "for l in layers_default:\n",
    "    label = f\"Layer {int(l)}\" if l != max_layer else \"All Layers (Concat)\"\n",
    "    layer_options.append({'label': label, 'value': l})\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Build the Dash App Layout\n",
    "# ------------------------------\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"MSE Normalization Dashboard\"\n",
    "\n",
    "app.layout = html.Div(\n",
    "    style={'fontFamily': 'Arial, sans-serif', 'margin': '20px'},\n",
    "    children=[\n",
    "        html.H1(\"MSE Normalization Dashboard\", style={'textAlign': 'center'}),\n",
    "        html.Div([\n",
    "            html.Label(\"Select Experiment:\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"experiment-dropdown\",\n",
    "                options=experiment_options,\n",
    "                value=default_experiment,\n",
    "                clearable=False,\n",
    "                style={\"width\": \"80%\", \"margin\": \"auto\"}\n",
    "            )\n",
    "        ], style={'margin-bottom': '20px'}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H3(\"Analysis Type\"),\n",
    "                dcc.Checklist(\n",
    "                    id='analysis-type-checklist',\n",
    "                    options=analysis_type_options,\n",
    "                    value=['trained', 'trained_shuffled', 'random'],\n",
    "                    labelStyle={'display': 'inline-block', 'margin-right': '15px'}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc', 'margin-right': '20px'}),\n",
    "            html.Div([\n",
    "                html.H3(\"Belief Type\"),\n",
    "                dcc.Checklist(\n",
    "                    id='belief-type-checklist',\n",
    "                    options=belief_type_options,\n",
    "                    value=['normalized', 'unnormalized'],\n",
    "                    labelStyle={'display': 'inline-block', 'margin-right': '15px'}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc', 'margin-right': '20px'}),\n",
    "            html.Div([\n",
    "                html.H3(\"Layer Selection\"),\n",
    "                dcc.Checklist(\n",
    "                    id='layer-checklist',\n",
    "                    options=layer_options,\n",
    "                    value=layers_default,\n",
    "                    labelStyle={'display': 'inline-block', 'margin-right': '15px'}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc'})\n",
    "        ], style={'display': 'flex', 'justifyContent': 'center', 'margin-bottom': '20px'}),\n",
    "        # --- New controls for normalization ---\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H3(\"Shuffle Baseline\"),\n",
    "                dcc.Dropdown(\n",
    "                    id=\"baseline-type-dropdown\",\n",
    "                    options=[\n",
    "                        {'label': 'Trained Shuffled', 'value': 'trained_shuffled'},\n",
    "                        {'label': 'Random', 'value': 'random'},\n",
    "                    ],\n",
    "                    value='trained_shuffled',\n",
    "                    clearable=False,\n",
    "                    style={\"width\": \"200px\"}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc', 'margin-right': '20px'}),\n",
    "            html.Div([\n",
    "                html.H3(\"Normalization Method\"),\n",
    "                dcc.Dropdown(\n",
    "                    id=\"normalization-method-dropdown\",\n",
    "                    options=[\n",
    "                        {'label': 'None (Raw MSE)', 'value': 'none'},\n",
    "                        {'label': 'Ratio', 'value': 'ratio'},\n",
    "                        {'label': 'Percent Difference', 'value': 'percent'},\n",
    "                        {'label': 'Z-Score', 'value': 'zscore'},\n",
    "                    ],\n",
    "                    value='none',\n",
    "                    clearable=False,\n",
    "                    style={\"width\": \"200px\"}\n",
    "                )\n",
    "            ], style={'padding': '10px', 'border': '1px solid #ccc'})\n",
    "        ], style={'display': 'flex', 'justifyContent': 'center', 'margin-bottom': '20px'}),\n",
    "        dcc.Graph(id='mse-graph')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Callbacks\n",
    "# ------------------------------\n",
    "\n",
    "# Update the available layer options when the experiment is changed.\n",
    "@app.callback(\n",
    "    Output('layer-checklist', 'options'),\n",
    "    Output('layer-checklist', 'value'),\n",
    "    Input('experiment-dropdown', 'value')\n",
    ")\n",
    "def update_layer_options(selected_experiment):\n",
    "    if not selected_experiment:\n",
    "        return [], []\n",
    "    try:\n",
    "        df_exp = pd.read_csv(selected_experiment)\n",
    "        def compute_x_value(row):\n",
    "            if row['random_or_trained'] == 'random':\n",
    "                return row['seed']\n",
    "            else:\n",
    "                try:\n",
    "                    return float(row['checkpoint'])\n",
    "                except:\n",
    "                    return None\n",
    "        df_exp['x_value'] = df_exp.apply(compute_x_value, axis=1)\n",
    "        layers_exp = sorted(df_exp['layer_index'].unique())\n",
    "        if not layers_exp:\n",
    "            return [], []\n",
    "        max_layer_exp = max(layers_exp)\n",
    "        opts = [{'label': f\"Layer {int(l)}\" if l != max_layer_exp else \"All Layers (Concat)\", 'value': l} for l in layers_exp]\n",
    "        return opts, layers_exp\n",
    "    except Exception as e:\n",
    "        print(\"Error updating layer options:\", e)\n",
    "        return [], []\n",
    "\n",
    "# Main callback for updating the graph.\n",
    "@app.callback(\n",
    "    Output('mse-graph', 'figure'),\n",
    "    Input('experiment-dropdown', 'value'),\n",
    "    Input('analysis-type-checklist', 'value'),\n",
    "    Input('belief-type-checklist', 'value'),\n",
    "    Input('layer-checklist', 'value'),\n",
    "    Input('baseline-type-dropdown', 'value'),\n",
    "    Input('normalization-method-dropdown', 'value')\n",
    ")\n",
    "def update_graph(selected_experiment, selected_analysis_types, selected_belief_types,\n",
    "                 selected_layers, baseline_type, normalization_method):\n",
    "    # If no experiment or if required selections are empty, return an empty figure.\n",
    "    if not selected_experiment or not selected_belief_types or not selected_layers:\n",
    "        return go.Figure()\n",
    "\n",
    "    try:\n",
    "        df_exp = pd.read_csv(selected_experiment)\n",
    "    except Exception as e:\n",
    "        print(\"Error reading CSV:\", e)\n",
    "        return go.Figure()\n",
    "\n",
    "    # Compute x_value: for non-random runs, use checkpoint (as float); for random, use seed.\n",
    "    def compute_x_value(row):\n",
    "        if row['random_or_trained'] == 'random':\n",
    "            return row['seed']\n",
    "        else:\n",
    "            try:\n",
    "                return float(row['checkpoint'])\n",
    "            except:\n",
    "                return None\n",
    "    df_exp['x_value'] = df_exp.apply(compute_x_value, axis=1)\n",
    "\n",
    "    # Filter data based on belief type and layer selection.\n",
    "    filtered = df_exp[\n",
    "        df_exp['norm_type'].isin(selected_belief_types) &\n",
    "        df_exp['layer_index'].isin(selected_layers)\n",
    "    ]\n",
    "\n",
    "    # If no normalization is requested, plot raw MSE for the selected analysis types.\n",
    "    if normalization_method == 'none':\n",
    "        # Further filter based on analysis types (raw view includes all types).\n",
    "        filtered = filtered[filtered['random_or_trained'].isin(selected_analysis_types)]\n",
    "        filtered = filtered.sort_values('x_value')\n",
    "        \n",
    "        # Determine x_range from non-random data.\n",
    "        non_random = filtered[filtered['random_or_trained'] != 'random']\n",
    "        if not non_random.empty:\n",
    "            x_min = non_random['x_value'].min()\n",
    "            x_max = non_random['x_value'].max()\n",
    "        else:\n",
    "            x_min = filtered['x_value'].min()\n",
    "            x_max = filtered['x_value'].max()\n",
    "        x_range = (x_min, x_max)\n",
    "        \n",
    "        # Color mapping based on layers.\n",
    "        all_layers = sorted(df_exp['layer_index'].unique())\n",
    "        if not all_layers:\n",
    "            return go.Figure()\n",
    "        max_layer_val = max(all_layers)\n",
    "        non_concat_layers = [l for l in all_layers if l != max_layer_val]\n",
    "        color_map = {}\n",
    "        for layer in all_layers:\n",
    "            if layer == max_layer_val:\n",
    "                color_map[layer] = 'black'\n",
    "            else:\n",
    "                if len(non_concat_layers) == 1:\n",
    "                    frac = 0.5\n",
    "                else:\n",
    "                    frac = non_concat_layers.index(layer) / (len(non_concat_layers) - 1) if len(non_concat_layers) > 1 else 0\n",
    "                sampled = px.colors.sample_colorscale(\"Oryel\", frac)\n",
    "                color_map[layer] = sampled[0]\n",
    "        \n",
    "        # Define line dash styles.\n",
    "        line_styles = {\n",
    "            'trained': 'solid',\n",
    "            'trained_shuffled': 'dash',\n",
    "            'random': 'dot'\n",
    "        }\n",
    "        \n",
    "        # Define belief type styles\n",
    "        belief_type_styles = {\n",
    "            'normalized': {'opacity': 1.0, 'width': 3},\n",
    "            'unnormalized': {'opacity': 0.6, 'width': 2}\n",
    "        }\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        grouped = filtered.groupby(['random_or_trained', 'norm_type', 'layer_index'])\n",
    "        for (analysis_type, norm_type, layer_index), group in grouped:\n",
    "            # Label the layer.\n",
    "            layer_label = f\"Layer {int(layer_index)}\" if layer_index != max_layer_val else \"All Layers (Concat)\"\n",
    "            trace_label = f\"{analysis_type.title()} | {norm_type.title()} | {layer_label}\"\n",
    "            trace_color = color_map.get(layer_index, \"black\")\n",
    "            \n",
    "            # Get belief type style\n",
    "            style = belief_type_styles[norm_type]\n",
    "            \n",
    "            if analysis_type == 'random':\n",
    "                # Aggregate random runs: show horizontal line (with SEM shading).\n",
    "                avg_MSE = group['MSE'].mean()\n",
    "                std_MSE = group['MSE'].std()\n",
    "                n = group.shape[0]\n",
    "                sem_MSE = std_MSE / math.sqrt(n) if n > 0 else 0\n",
    "                x_shaded = [x_range[0], x_range[1], x_range[1], x_range[0]]\n",
    "                y_shaded = [avg_MSE - sem_MSE, avg_MSE - sem_MSE, avg_MSE + sem_MSE, avg_MSE + sem_MSE]\n",
    "                try:\n",
    "                    r = int(trace_color[1:3], 16)\n",
    "                    g = int(trace_color[3:5], 16)\n",
    "                    b = int(trace_color[5:7], 16)\n",
    "                    fill_color = f\"rgba({r},{g},{b},0.2)\"\n",
    "                except:\n",
    "                    fill_color = \"rgba(0,0,0,0.2)\"\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=x_shaded,\n",
    "                    y=y_shaded,\n",
    "                    fill=\"toself\",\n",
    "                    fillcolor=fill_color,\n",
    "                    line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                    showlegend=False,\n",
    "                    hoverinfo='skip'\n",
    "                ))\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=[x_range[0], x_range[1]],\n",
    "                    y=[avg_MSE, avg_MSE],\n",
    "                    mode='lines',\n",
    "                    name=trace_label,\n",
    "                    line=dict(\n",
    "                        color=trace_color, \n",
    "                        dash=line_styles[analysis_type], \n",
    "                        width=style['width']\n",
    "                    ),\n",
    "                    opacity=style['opacity'],\n",
    "                    hovertemplate=(\n",
    "                        f\"Analysis Type: {analysis_type}<br>\" +\n",
    "                        f\"Belief Type: {norm_type}<br>\" +\n",
    "                        f\"{layer_label}<br>\" +\n",
    "                        f\"Avg MSE: {avg_MSE:.5f}<br>\" +\n",
    "                        f\"SEM: {sem_MSE:.5f}<extra></extra>\"\n",
    "                    )\n",
    "                ))\n",
    "            else:\n",
    "                group = group.sort_values('x_value')\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=group['x_value'],\n",
    "                    y=group['MSE'],\n",
    "                    mode='lines+markers',\n",
    "                    name=trace_label,\n",
    "                    line=dict(\n",
    "                        color=trace_color, \n",
    "                        dash=line_styles[analysis_type],\n",
    "                        width=style['width']\n",
    "                    ),\n",
    "                    opacity=style['opacity'],\n",
    "                    marker=dict(symbol='circle', size=5),\n",
    "                    hovertemplate=(\n",
    "                        f\"Analysis Type: {analysis_type}<br>\" +\n",
    "                        f\"Belief Type: {norm_type}<br>\" +\n",
    "                        f\"{layer_label}<br>\" +\n",
    "                        \"X: %{x}<br>\" +\n",
    "                        \"MSE: %{y:.5f}<extra></extra>\"\n",
    "                    )\n",
    "                ))\n",
    "        fig.update_layout(\n",
    "            title=\"MSE vs. Checkpoint/Seed (Raw Values)\",\n",
    "            xaxis_title=\"Checkpoint (for Trained) or Seed (for Random)\",\n",
    "            yaxis_title=\"MSE (log scale)\",\n",
    "            yaxis_type=\"log\",\n",
    "            legend_title=\"Trace Groups\",\n",
    "            margin={'l': 50, 'r': 50, 't': 50, 'b': 50}\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "    else:\n",
    "        # When normalization is requested, we compare only the trained data,\n",
    "        # normalized by the chosen baseline.\n",
    "        # Filter out trained runs.\n",
    "        trained_data = filtered[filtered['random_or_trained'] == 'trained']\n",
    "        if trained_data.empty:\n",
    "            return go.Figure()\n",
    "\n",
    "        # Get baseline data using the selected baseline type.\n",
    "        baseline_data = filtered[filtered['random_or_trained'] == baseline_type]\n",
    "        if baseline_data.empty:\n",
    "            return go.Figure()\n",
    "\n",
    "        # Depending on the baseline type, define the merge key.\n",
    "        # For \"trained_shuffled\", we assume matching checkpoints (x_value) exist.\n",
    "        # For \"random\", we aggregate baseline data by layer and norm_type.\n",
    "        if baseline_type == 'trained_shuffled':\n",
    "            merged = pd.merge(\n",
    "                trained_data,\n",
    "                baseline_data,\n",
    "                on=['x_value', 'layer_index', 'norm_type'],\n",
    "                suffixes=('', '_baseline')\n",
    "            )\n",
    "        elif baseline_type == 'random':\n",
    "            # Aggregate baseline: compute mean and std over the group.\n",
    "            baseline_stats = baseline_data.groupby(['layer_index', 'norm_type'])['MSE']\\\n",
    "                                .agg(['mean', 'std']).reset_index()\n",
    "            merged = pd.merge(\n",
    "                trained_data,\n",
    "                baseline_stats,\n",
    "                on=['layer_index', 'norm_type'],\n",
    "                how='left'\n",
    "            )\n",
    "            # Rename for consistency.\n",
    "            merged.rename(columns={'mean': 'MSE_baseline', 'std': 'std_baseline'}, inplace=True)\n",
    "        else:\n",
    "            merged = pd.DataFrame()  # Should not occur.\n",
    "\n",
    "        if merged.empty:\n",
    "            return go.Figure()\n",
    "\n",
    "        # Compute the normalized MSE based on the chosen method.\n",
    "        if normalization_method == 'ratio':\n",
    "            merged['normalized_MSE'] = merged.apply(\n",
    "                lambda row: 1 - row['MSE'] / row['MSE_baseline'] if row['MSE_baseline'] != 0 else None,\n",
    "                axis=1\n",
    "            )\n",
    "            y_label = \"Normalized MSE (Trained / Baseline)\"\n",
    "        elif normalization_method == 'percent':\n",
    "            merged['normalized_MSE'] = merged.apply(\n",
    "                lambda row: 100 * (row['MSE'] - row['MSE_baseline']) / row['MSE_baseline']\n",
    "                if row['MSE_baseline'] != 0 else None,\n",
    "                axis=1\n",
    "            )\n",
    "            y_label = \"Percent Difference (%)\"\n",
    "        elif normalization_method == 'zscore':\n",
    "            # For zscore, if baseline is \"random\" we use the aggregated std;\n",
    "            # if baseline is \"trained_shuffled\" and if there are multiple entries per checkpoint, it will work similarly.\n",
    "            if baseline_type == 'random':\n",
    "                merged['normalized_MSE'] = merged.apply(\n",
    "                    lambda row: (row['MSE'] - row['MSE_baseline']) / row['std_baseline']\n",
    "                    if row['std_baseline'] != 0 else None,\n",
    "                    axis=1\n",
    "                )\n",
    "            else:\n",
    "                # For \"trained_shuffled\" we might have only one baseline value per checkpoint.\n",
    "                merged['normalized_MSE'] = None  # Could be skipped or handled differently.\n",
    "            y_label = \"Z-Score (Trained relative to Baseline)\"\n",
    "        else:\n",
    "            merged['normalized_MSE'] = merged['MSE']  # Fallback, though this branch should not occur.\n",
    "            y_label = \"MSE\"\n",
    "\n",
    "        # Sort merged data by x_value.\n",
    "        merged = merged.sort_values('x_value')\n",
    "\n",
    "        # Set up color mapping (using the overall available layers in the full dataset).\n",
    "        all_layers = sorted(df_exp['layer_index'].unique())\n",
    "        if not all_layers:\n",
    "            return go.Figure()\n",
    "        max_layer_val = max(all_layers)\n",
    "        non_concat_layers = [l for l in all_layers if l != max_layer_val]\n",
    "        color_map = {}\n",
    "        for layer in all_layers:\n",
    "            if layer == max_layer_val:\n",
    "                color_map[layer] = 'black'\n",
    "            else:\n",
    "                if len(non_concat_layers) == 1:\n",
    "                    frac = 0.5\n",
    "                else:\n",
    "                    frac = non_concat_layers.index(layer) / (len(non_concat_layers) - 1) if len(non_concat_layers) > 1 else 0\n",
    "                sampled = px.colors.sample_colorscale(\"Oryel\", frac)\n",
    "                color_map[layer] = sampled[0]\n",
    "\n",
    "        # Define belief type styles\n",
    "        belief_type_styles = {\n",
    "            'normalized': {'opacity': 1.0, 'width': 3},\n",
    "            'unnormalized': {'opacity': 0.6, 'width': 2}\n",
    "        }\n",
    "\n",
    "        fig = go.Figure()\n",
    "        # Group the merged data by norm_type and layer_index.\n",
    "        grouped = merged.groupby(['norm_type', 'layer_index'])\n",
    "        for (norm_type, layer_index), group in grouped:\n",
    "            layer_label = f\"Layer {int(layer_index)}\" if layer_index != max_layer_val else \"All Layers (Concat)\"\n",
    "            trace_label = f\"Trained | {norm_type.title()} | {layer_label} (Normalized by {baseline_type})\"\n",
    "            trace_color = color_map.get(layer_index, \"black\")\n",
    "            \n",
    "            # Get belief type style\n",
    "            style = belief_type_styles[norm_type]\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=group['x_value'],\n",
    "                y=group['normalized_MSE'],\n",
    "                mode='lines+markers',\n",
    "                name=trace_label,\n",
    "                line=dict(color=trace_color, dash='solid', width=style['width']),\n",
    "                opacity=style['opacity'],\n",
    "                marker=dict(symbol='circle', size=5),\n",
    "                hovertemplate=\"Checkpoint: %{x}<br>Normalized MSE: %{y:.5f}<extra></extra>\"\n",
    "            ))\n",
    "        fig.update_layout(\n",
    "            title=\"Normalized MSE vs. Checkpoint (Trained Models)\",\n",
    "            xaxis_title=\"Checkpoint (for Trained models)\",\n",
    "            yaxis_title=y_label,\n",
    "            margin={'l': 50, 'r': 50, 't': 50, 'b': 50}\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Run the App\n",
    "# ------------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epsilon-machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
