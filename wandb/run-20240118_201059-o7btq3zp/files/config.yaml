wandb_version: 1

learning_rate:
  desc: null
  value: 1.0e-05
weight_decay:
  desc: null
  value: 0
_wandb:
  desc: null
  value:
    python_version: 3.11.7
    cli_version: 0.16.1
    framework: huggingface
    huggingface_version: 4.36.2
    is_jupyter_run: true
    is_kaggle_kernel: false
    start_time: 1705637459.197808
    t:
      1:
      - 1
      - 11
      - 49
      - 51
      - 55
      - 71
      2:
      - 1
      - 11
      - 49
      - 51
      - 55
      - 71
      3:
      - 2
      - 17
      - 23
      - 37
      4: 3.11.7
      5: 0.16.1
      6: 4.36.2
      8:
      - 1
      - 4
      - 5
      13: darwin-arm64
model_config:
  desc: null
  value:
    n_layers: 2
    d_model: 16
    n_ctx: 10
    d_head: 4
    model_name: custom
    n_heads: 4
    d_mlp: 64
    act_fn: relu
    d_vocab: 2
    eps: 1.0e-05
    use_attn_result: false
    use_attn_scale: true
    use_split_qkv_input: false
    use_hook_mlp_in: false
    use_attn_in: false
    use_local_attn: false
    original_architecture: null
    from_checkpoint: false
    checkpoint_index: null
    checkpoint_label_type: null
    checkpoint_value: null
    tokenizer_name: null
    window_size: null
    attn_types: null
    init_mode: gpt2
    normalization_type: null
    device: mps
    n_devices: 1
    attention_dir: causal
    attn_only: false
    seed: 42
    initializer_range: 0.2
    init_weights: true
    scale_attn_by_inverse_layer_idx: false
    positional_embedding_type: standard
    final_rms: false
    d_vocab_out: 2
    parallel_attn_mlp: false
    rotary_dim: null
    n_params: 6144
    use_hook_tokens: false
    gated_mlp: false
    default_prepend_bos: true
    dtype: torch.float32
    tokenizer_prepends_bos: null
    post_embedding_ln: false
train_config:
  desc: null
  value:
    batch_size: 32
    sequence_length: 500
    num_sequences: 100
    num_epochs: 200
    learning_rate: 0.00015
    weight_decay: 0
