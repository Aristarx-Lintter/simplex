Traceback (most recent call last):
  File "/Users/adamimos/Documents/GitHub/epsilon-transformers/./test.py", line 75, in sweep_train
    train_loss_per_position, train_loss_mean, test_loss_per_position, test_loss_mean = train_epoch(network, optimizer,
                                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adamimos/Documents/GitHub/epsilon-transformers/./test.py", line 206, in train_epoch
    optimizer.step()
  File "/Users/adamimos/anaconda3/envs/epsilon-machine/lib/python3.11/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adamimos/anaconda3/envs/epsilon-machine/lib/python3.11/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adamimos/anaconda3/envs/epsilon-machine/lib/python3.11/site-packages/torch/optim/adam.py", line 163, in step
    adam(
  File "/Users/adamimos/anaconda3/envs/epsilon-machine/lib/python3.11/site-packages/torch/optim/adam.py", line 311, in adam
    func(params,
  File "/Users/adamimos/anaconda3/envs/epsilon-machine/lib/python3.11/site-packages/torch/optim/adam.py", line 385, in _single_tensor_adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)
Exception