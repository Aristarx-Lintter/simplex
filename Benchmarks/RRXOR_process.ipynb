{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Random-Random-XOR Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_RRXOR_data(total_length):\n",
    "    output = []\n",
    "    \n",
    "    while len(output) < total_length+3:\n",
    "        bit1 = random.randint(0, 1)\n",
    "        bit2 = random.randint(0, 1)\n",
    "        xor_result = bit1 ^ bit2\n",
    "        output.extend([bit1, bit2, xor_result])\n",
    "    \n",
    "    # Start the sequence randomly at bit 1,2 or 3\n",
    "    start_index = random.randint(0, 2)\n",
    "    output = output[start_index:]\n",
    "\n",
    "    # Return the sequence up to the desired total length\n",
    "    return output[:total_length]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1010111011100001011101101100001011010110110110110110111011100000110111101010000110001010001100111011101101100111101011011010110000000110000110000110000111100111011100111101011010001011101100111100000001011010000110110000000111010110000111101101101010000000110110111011101101010000110001010111011010001101100001011010001100110110001100110111010111101011010001010000110110110000000001011100111101101010000111010110000001011101100000000000000000001100001100111100110110001101101010001100001100000110000110111100000110001011011101010111010001100000001011100000001010110111011011101011011010111011100111010001100000000000110110001100110111010000000111010110001010001101101100001101011011100000111100000001100000110001100000111011101011100000111011010111010110111011101011101101010111100001101100110000111011101101101011011100001010000000111010000000001100111010001101010110001010110110000110001011010111101011101100111101011010001010110111010110110001101011101011101011011010001100001101101011100110110001'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([str(x) for x in generate_RRXOR_data(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_transformer import MultilayerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a config for the transformer\n",
    "config = {\n",
    "    'd_vocab': 2,\n",
    "    'd_model': 16,\n",
    "    'input_size': 4, # context length\n",
    "    'd_head': 16,\n",
    "    'n_head': 1,\n",
    "    'd_mlp': 4*16,\n",
    "    'n_layers': 1\n",
    "    }\n",
    "\n",
    "batch_size = 32\n",
    "sequence_length = 1000\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, batch_size):\n",
    "    \"\"\"Create batches from the data.\"\"\"\n",
    "    return [data[i:i+batch_size] for i in range(0, len(data), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process into Input-Target sequences for parallel prediction\n",
    "input_size = config['input_size']  # as per your model definition\n",
    "inputs, targets = [], []\n",
    "\n",
    "for i in range(len(sequence) - input_size):\n",
    "    input_seq = sequence[i:i+input_size]\n",
    "    target_seq = sequence[i+1:i+input_size+1]  # Shifted by one position for next bit prediction\n",
    "    inputs.append([int(bit) for bit in input_seq])\n",
    "    targets.append([int(bit) for bit in target_seq])\n",
    "\n",
    "# Split into Training and Test Data (e.g., 80% train, 20% test)\n",
    "split_idx = int(0.8 * len(inputs))\n",
    "train_inputs, train_targets = inputs[:split_idx], targets[:split_idx]\n",
    "test_inputs, test_targets = inputs[split_idx:], targets[split_idx:]\n",
    "\n",
    "# Convert to tensors for PyTorch\n",
    "train_inputs, train_targets = torch.tensor(train_inputs, dtype=torch.long), torch.tensor(train_targets, dtype=torch.long)\n",
    "test_inputs, test_targets = torch.tensor(test_inputs, dtype=torch.long), torch.tensor(test_targets, dtype=torch.long)\n",
    "\n",
    "# Create batches for training and test data\n",
    "train_input_batches = create_batches(train_inputs, batch_size)\n",
    "train_target_batches = create_batches(train_targets, batch_size)\n",
    "test_input_batches = create_batches(test_inputs, batch_size)\n",
    "test_target_batches = create_batches(test_targets, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([1, 0, 1, 1])\n",
      "Y: tensor([0, 1, 1, 0])\n",
      "\n",
      "X: tensor([0, 1, 1, 0])\n",
      "Y: tensor([1, 1, 0, 1])\n",
      "\n",
      "X: tensor([1, 1, 0, 1])\n",
      "Y: tensor([1, 0, 1, 1])\n",
      "\n",
      "X: tensor([1, 0, 1, 1])\n",
      "Y: tensor([0, 1, 1, 0])\n",
      "\n",
      "X: tensor([0, 1, 1, 0])\n",
      "Y: tensor([1, 1, 0, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print a few examples from the training data\n",
    "for i in range(5):\n",
    "    print('X:', train_inputs[i])\n",
    "    print('Y:', train_targets[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "# 3. Model Definition\n",
    "\n",
    "model = MultilayerTransformer(**config)\n",
    "\n",
    "# print if cuda is available\n",
    "print('CUDA Available:', torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "def compute_accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    Compute accuracy for predictions against targets.\n",
    "    \"\"\"\n",
    "    correct_preds = (predictions == targets).float()\n",
    "    accuracy = correct_preds.mean().item()\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "--------------------------------------------------------------------------------\n",
      "| Epoch | Training Acc | Training Loss | Overall Test Acc | Last Bit Test Acc |\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   1   |    50.73%    |    0.6945     |      47.28%       |      52.63%      |\n",
      "|   2   |    53.54%    |    0.6904     |      54.24%       |      56.30%      |\n",
      "|   3   |    56.72%    |    0.6860     |      55.67%       |      58.38%      |\n",
      "|   4   |    62.36%    |    0.6793     |      58.69%       |      66.91%      |\n",
      "|   5   |    66.51%    |    0.6710     |      60.85%       |      66.91%      |\n",
      "|   6   |    66.51%    |    0.6638     |      60.85%       |      66.91%      |\n",
      "|   7   |    66.51%    |    0.6592     |      60.85%       |      66.91%      |\n",
      "|   8   |    66.51%    |    0.6573     |      60.85%       |      66.91%      |\n",
      "|   9   |    66.51%    |    0.6566     |      60.85%       |      66.91%      |\n",
      "|  10   |    66.51%    |    0.6562     |      60.85%       |      66.91%      |\n",
      "|  11   |    66.51%    |    0.6560     |      60.85%       |      66.91%      |\n",
      "|  12   |    66.51%    |    0.6559     |      60.85%       |      66.91%      |\n",
      "|  13   |    66.51%    |    0.6557     |      60.85%       |      66.91%      |\n",
      "|  14   |    66.51%    |    0.6556     |      60.85%       |      66.91%      |\n",
      "|  15   |    66.51%    |    0.6555     |      60.85%       |      66.91%      |\n",
      "|  16   |    66.51%    |    0.6555     |      60.85%       |      66.91%      |\n",
      "|  17   |    66.51%    |    0.6554     |      60.85%       |      66.91%      |\n",
      "|  18   |    66.51%    |    0.6553     |      60.85%       |      66.91%      |\n",
      "|  19   |    66.51%    |    0.6553     |      60.85%       |      66.91%      |\n",
      "|  20   |    66.51%    |    0.6553     |      60.85%       |      66.91%      |\n",
      "|  21   |    66.51%    |    0.6552     |      60.85%       |      66.91%      |\n",
      "|  22   |    66.51%    |    0.6552     |      60.85%       |      66.91%      |\n",
      "|  23   |    66.51%    |    0.6552     |      60.85%       |      66.91%      |\n",
      "|  24   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  25   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  26   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  27   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  28   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  29   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  30   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  31   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  32   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  33   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  34   |    66.51%    |    0.6552     |      60.85%       |      66.91%      |\n",
      "|  35   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  36   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  37   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  38   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  39   |    66.51%    |    0.6551     |      60.85%       |      66.91%      |\n",
      "|  40   |    66.51%    |    0.6550     |      60.85%       |      66.91%      |\n",
      "|  41   |    66.51%    |    0.6550     |      60.85%       |      66.91%      |\n",
      "|  42   |    66.51%    |    0.6550     |      60.85%       |      66.91%      |\n",
      "|  43   |    66.51%    |    0.6550     |      60.85%       |      66.91%      |\n",
      "|  44   |    66.51%    |    0.6549     |      60.85%       |      66.91%      |\n",
      "|  45   |    66.51%    |    0.6549     |      60.85%       |      66.91%      |\n",
      "|  46   |    66.51%    |    0.6549     |      60.85%       |      66.91%      |\n",
      "|  47   |    66.51%    |    0.6549     |      60.85%       |      66.91%      |\n",
      "|  48   |    66.51%    |    0.6548     |      60.85%       |      66.91%      |\n",
      "|  49   |    66.51%    |    0.6548     |      60.85%       |      66.91%      |\n",
      "|  50   |    66.51%    |    0.6548     |      60.85%       |      66.91%      |\n",
      "|  51   |    66.51%    |    0.6547     |      60.85%       |      66.91%      |\n",
      "|  52   |    66.51%    |    0.6547     |      60.85%       |      66.91%      |\n",
      "|  53   |    66.51%    |    0.6547     |      60.85%       |      66.91%      |\n",
      "|  54   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  55   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  56   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  57   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  58   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  59   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  60   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  61   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  62   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  63   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  64   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  65   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  66   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  67   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  68   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  69   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  70   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  71   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  72   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  73   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  74   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  75   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  76   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  77   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  78   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  79   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  80   |    66.51%    |    0.6545     |      60.85%       |      66.91%      |\n",
      "|  81   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  82   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  83   |    66.51%    |    0.6546     |      60.85%       |      66.91%      |\n",
      "|  84   |    66.51%    |    0.6545     |      62.03%       |      66.91%      |\n",
      "|  85   |    66.51%    |    0.6542     |      62.03%       |      66.91%      |\n",
      "|  86   |    66.51%    |    0.6522     |      63.01%       |      66.91%      |\n",
      "|  87   |    66.51%    |    0.6478     |      63.01%       |      66.91%      |\n",
      "|  88   |    66.51%    |    0.6458     |      63.01%       |      66.91%      |\n",
      "|  89   |    66.51%    |    0.6451     |      63.01%       |      66.91%      |\n",
      "|  90   |    66.51%    |    0.6447     |      63.01%       |      66.91%      |\n",
      "|  91   |    66.51%    |    0.6446     |      63.01%       |      66.91%      |\n",
      "|  92   |    66.51%    |    0.6445     |      63.01%       |      66.91%      |\n",
      "|  93   |    66.51%    |    0.6445     |      63.01%       |      66.91%      |\n",
      "|  94   |    66.51%    |    0.6445     |      63.01%       |      66.91%      |\n",
      "|  95   |    66.51%    |    0.6445     |      63.01%       |      66.91%      |\n",
      "|  96   |    66.51%    |    0.6444     |      63.01%       |      66.91%      |\n",
      "|  97   |    66.51%    |    0.6443     |      63.01%       |      66.91%      |\n",
      "|  98   |    66.51%    |    0.6443     |      63.01%       |      66.91%      |\n",
      "|  99   |    66.51%    |    0.6442     |      63.01%       |      66.91%      |\n",
      "|  100  |    66.51%    |    0.6442     |      63.01%       |      66.91%      |\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the table header\n",
    "print(\"\\nTraining Results:\")\n",
    "print(\"-\" * 80)\n",
    "header = \"| Epoch | Training Acc | Training Loss | Overall Test Acc | Last Bit Test Acc |\"\n",
    "print(header)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Adjusted training loop with tabulated printing and accuracy reporting on the test set at the end of each epoch\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()  # set the model to training mode\n",
    "\n",
    "    running_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch_inputs, batch_targets in zip(train_input_batches, train_target_batches):\n",
    "        if torch.cuda.is_available():\n",
    "            batch_inputs, batch_targets = batch_inputs.cuda(), batch_targets.cuda()\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs.view(-1, config['d_vocab']), batch_targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep track of accuracy and number of batches\n",
    "        running_acc += compute_accuracy(torch.argmax(outputs, dim=-1)[:,-1], batch_targets[:,-1])\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Calculate training results after each epoch\n",
    "    avg_training_acc = running_acc / num_batches\n",
    "    \n",
    "    # Evaluation on test set after each epoch\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    with torch.no_grad():  # no gradients needed for evaluation\n",
    "        overall_accuracies = []\n",
    "        last_bit_accuracies = []\n",
    "\n",
    "        # Iterate over test batches\n",
    "        for idx, (batch_inputs, batch_targets) in enumerate(zip(test_input_batches, test_target_batches)):\n",
    "            if torch.cuda.is_available():\n",
    "                batch_inputs, batch_targets = batch_inputs.cuda(), batch_targets.cuda()\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(batch_inputs)\n",
    "            predicted_classes = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            # Compute overall accuracy\n",
    "            overall_accuracy = compute_accuracy(predicted_classes, batch_targets)\n",
    "            overall_accuracies.append(overall_accuracy)\n",
    "\n",
    "            # Compute accuracy for the last bit\n",
    "            last_bit_accuracy = compute_accuracy(predicted_classes[:, -1], batch_targets[:, -1])\n",
    "            last_bit_accuracies.append(last_bit_accuracy)\n",
    "\n",
    "        # Calculate average accuracies for the entire test set after each epoch\n",
    "        avg_overall_accuracy = sum(overall_accuracies) / len(overall_accuracies)\n",
    "        avg_last_bit_accuracy = sum(last_bit_accuracies) / len(last_bit_accuracies)\n",
    "\n",
    "    # Print the results in a tabulated format\n",
    "    row = f\"| {epoch+1:^5} | {avg_training_acc:^12.2%} | {loss.item():^13.4f} | {avg_overall_accuracy:^17.2%} | {avg_last_bit_accuracy:^16.2%} |\"\n",
    "    print(row)\n",
    "\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7992, 9])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
