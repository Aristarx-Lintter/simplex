{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6ad83-dfb8-4c07-bc38-9942ad676097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5e779f-cf0f-4526-962d-5010ee438c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from epsilon_transformers.process.transition_matrices import mess3\n",
    "from epsilon_transformers.process.GHMM import TransitionMatrixGHMM\n",
    "\n",
    "# Параметры Mess3\n",
    "T = mess3(x=0.05, a=0.85)\n",
    "\n",
    "# GHMM над заданной матрицей переходов\n",
    "ghmm = TransitionMatrixGHMM(T)\n",
    "\n",
    "# Пошаговая генерация length токенов\n",
    "length = 20\n",
    "sequence = list(ghmm.yield_emissions(sequence_len=length))\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128c1777-6beb-4ea5-b6e8-06c1e7b65e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process initialized successfully!\n",
      "X: [3, 2, 2, 0, 0, 0, 1, 0]\n",
      "Y: [2, 2, 0, 0, 0, 1, 0, 0]\n",
      "loss_lower_bound: [1.0986123085021973, 0.8577190041542053, 0.8133556842803955, 0.7981176376342773, 0.7947399616241455, 0.7937828302383423, 0.793542742729187, 0.7934796810150146]\n",
      "d_vocab: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from epsilon_transformers.training.dataloader import get_dataloader_and_loss_lower_bound_from_process\n",
    "\n",
    "process_params = {\"name\": \"mess3\", \"x\": 0.05, \"a\": 0.85}\n",
    "\n",
    "# n_ctx — длина контекста (включает BOS, если bos=True)\n",
    "dataloader, loss_lower_bound, d_vocab = get_dataloader_and_loss_lower_bound_from_process(\n",
    "    process_params=process_params,\n",
    "    n_ctx=8,\n",
    "    bos=True,\n",
    "    batches_per_epoch=1,\n",
    "    batch_size=1,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Получаем один батч и смотрим на последовательности X (вход) и Y (следующий токен)\n",
    "X, Y = next(iter(dataloader))\n",
    "print(\"X:\", X.squeeze(0).tolist())\n",
    "print(\"Y:\", Y.squeeze(0).tolist())\n",
    "print(\"loss_lower_bound:\", loss_lower_bound.tolist())\n",
    "print(\"d_vocab:\", d_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5707d7-7b9e-4f6b-876a-83c1faf73b57",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2292599-fb0d-4860-823a-71508bd10a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, torch.Size([4096, 7]), torch.Size([4096, 7]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from epsilon_transformers.process.transition_matrices import mess3, tom_quantum\n",
    "from epsilon_transformers.process.GHMM import TransitionMatrixGHMM\n",
    "\n",
    "# Фиксируем сиды\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Процессы\n",
    "T_mess = mess3(x=0.05, a=0.85)          # 3 символа\n",
    "T_bloch = tom_quantum(alpha=2.5, beta=0.3)  # 4 символа (Bloch Walk)\n",
    "ghmm_mess = TransitionMatrixGHMM(T_mess)\n",
    "ghmm_bloch = TransitionMatrixGHMM(T_bloch)\n",
    "\n",
    "# Настройки\n",
    "seq_len = 8                    # Рекомендуемое короткое окно\n",
    "num_seqs = 4096                # Небольшой датасет\n",
    "vocab_mess, vocab_bloch = 3, 4\n",
    "vocab_size = vocab_mess * vocab_bloch  # 12\n",
    "\n",
    "def sample_sequence(ghmm, length):\n",
    "    return list(ghmm.yield_emissions(sequence_len=length))\n",
    "\n",
    "def pair_to_token(mess_tok, bloch_tok):\n",
    "    return mess_tok * vocab_bloch + bloch_tok\n",
    "\n",
    "# Генерация независимых пар и склейка токенов (декартово произведение покомпонентно во времени)\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for _ in range(num_seqs):\n",
    "    s_m = sample_sequence(ghmm_mess, seq_len)\n",
    "    s_b = sample_sequence(ghmm_bloch, seq_len)\n",
    "    s_c = [pair_to_token(m, b) for m, b in zip(s_m, s_b)]  # 0..11\n",
    "\n",
    "    x = s_c[:-1]  # вход\n",
    "    y = s_c[1:]   # цель (next token)\n",
    "    X_list.append(x)\n",
    "    Y_list.append(y)\n",
    "\n",
    "X = torch.tensor(X_list, dtype=torch.long)  # [N, seq_len-1]\n",
    "Y = torch.tensor(Y_list, dtype=torch.long)  # [N, seq_len-1]\n",
    "\n",
    "# Трейн/валид сплит\n",
    "N = X.size(0)\n",
    "idx = torch.randperm(N)\n",
    "split = int(0.9 * N)\n",
    "train_idx, val_idx = idx[:split], idx[split:]\n",
    "\n",
    "train_ds = TensorDataset(X[train_idx], Y[train_idx])\n",
    "val_ds = TensorDataset(X[val_idx], Y[val_idx])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "vocab_size, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b023ec5-007e-4b21-b522-37c1325ea9a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 4,  9,  9,  8, 11,  8,  4],\n",
       "         [ 1,  3,  2,  1,  2,  2,  3],\n",
       "         [ 2,  6,  6,  7,  0,  7,  7],\n",
       "         [ 3,  3,  0,  5,  3,  0,  9],\n",
       "         [ 0,  3,  1,  3,  0,  1,  3],\n",
       "         [ 0,  4,  0,  2,  7,  7,  3],\n",
       "         [ 1,  2,  3,  3,  3, 11,  9],\n",
       "         [10,  9,  7, 10,  9, 10,  5],\n",
       "         [ 7,  7,  4,  7,  5, 11,  7],\n",
       "         [ 8,  7,  7,  6, 11, 11, 11],\n",
       "         [ 2,  1,  3,  7,  3,  2,  2],\n",
       "         [ 0,  8,  4,  8,  0,  0,  3],\n",
       "         [ 6,  5,  8, 11,  2,  9,  8],\n",
       "         [11,  3, 11,  8,  8,  3,  0],\n",
       "         [ 8, 10,  9,  0,  2,  3,  7],\n",
       "         [ 0,  4,  5,  7,  7,  6,  4],\n",
       "         [ 3,  3,  0,  2,  2,  3,  0],\n",
       "         [ 2,  3,  2,  2,  4,  2,  8],\n",
       "         [ 5,  6,  5,  2,  4,  5,  4],\n",
       "         [ 5,  4,  6,  4,  2,  0,  1],\n",
       "         [10,  1,  2,  6,  1, 11,  3],\n",
       "         [ 5, 10,  7,  0,  4, 10,  4],\n",
       "         [ 7,  4,  5,  7,  5,  6, 10],\n",
       "         [ 7,  6,  5,  5,  4,  5,  5],\n",
       "         [ 6,  1,  2,  1,  4, 11,  2],\n",
       "         [11, 11,  9,  5, 10,  9, 10],\n",
       "         [ 9,  9, 11, 10, 11, 11, 10],\n",
       "         [ 2,  5,  9,  7,  1,  6,  9],\n",
       "         [ 5,  7,  5,  5,  6, 11, 10],\n",
       "         [ 7, 11,  9, 11, 11, 11,  3],\n",
       "         [11,  2,  5,  0,  1,  1,  1],\n",
       "         [ 7,  2, 10,  3,  2,  0,  1],\n",
       "         [ 2,  3,  2,  3,  4,  1,  2],\n",
       "         [ 4,  5,  4,  5,  3,  4, 11],\n",
       "         [ 4, 11,  4,  6,  9,  5,  5],\n",
       "         [ 8, 11,  9,  8, 10,  8,  9],\n",
       "         [11,  8,  9,  3,  1,  1,  0],\n",
       "         [ 6,  6,  5,  5,  3,  4,  5],\n",
       "         [11, 11,  9, 10, 11,  9, 11],\n",
       "         [ 0,  3,  8,  2, 11,  4,  8],\n",
       "         [ 2,  0,  2,  3,  5,  1,  1],\n",
       "         [ 5,  5,  9,  4,  7,  7,  4],\n",
       "         [ 0, 10,  0,  0,  9,  3,  1],\n",
       "         [10,  3, 11, 10,  4,  4,  5],\n",
       "         [11,  8,  8, 11,  8,  8,  4],\n",
       "         [ 7,  9, 10, 11, 10,  8,  9],\n",
       "         [ 2,  1,  3,  1, 10,  0,  1],\n",
       "         [ 4,  4,  7,  2,  2,  0,  8],\n",
       "         [ 4,  4,  6,  5,  4,  4, 11],\n",
       "         [ 9, 11,  5,  9,  8, 10,  9],\n",
       "         [ 3,  1,  1,  3,  0,  2, 11],\n",
       "         [ 7,  1,  0,  3,  0,  0,  0],\n",
       "         [ 5,  0,  4,  4,  5,  7,  4],\n",
       "         [ 6,  4,  1,  2,  1,  1,  0],\n",
       "         [ 6,  6, 10, 11,  9,  7, 11],\n",
       "         [ 7,  5,  4,  5,  6,  7,  4],\n",
       "         [ 5,  2,  5,  4,  9,  7,  5],\n",
       "         [11, 11,  8,  9,  3, 11, 11],\n",
       "         [ 3,  5,  1,  3,  4,  3,  1],\n",
       "         [ 8,  1,  1,  3,  0,  1,  2],\n",
       "         [ 2,  1,  3,  5,  4,  4,  5],\n",
       "         [ 9,  9, 11,  9,  7, 10,  7],\n",
       "         [ 6,  7,  7,  0,  3,  7,  5],\n",
       "         [10, 10,  9,  8, 11, 10,  0]]),\n",
       " tensor([[ 9,  9,  8, 11,  8,  4,  6],\n",
       "         [ 3,  2,  1,  2,  2,  3,  0],\n",
       "         [ 6,  6,  7,  0,  7,  7,  0],\n",
       "         [ 3,  0,  5,  3,  0,  9,  3],\n",
       "         [ 3,  1,  3,  0,  1,  3,  0],\n",
       "         [ 4,  0,  2,  7,  7,  3,  1],\n",
       "         [ 2,  3,  3,  3, 11,  9, 11],\n",
       "         [ 9,  7, 10,  9, 10,  5,  5],\n",
       "         [ 7,  4,  7,  5, 11,  7,  7],\n",
       "         [ 7,  7,  6, 11, 11, 11,  8],\n",
       "         [ 1,  3,  7,  3,  2,  2,  1],\n",
       "         [ 8,  4,  8,  0,  0,  3,  9],\n",
       "         [ 5,  8, 11,  2,  9,  8, 10],\n",
       "         [ 3, 11,  8,  8,  3,  0,  2],\n",
       "         [10,  9,  0,  2,  3,  7, 11],\n",
       "         [ 4,  5,  7,  7,  6,  4,  7],\n",
       "         [ 3,  0,  2,  2,  3,  0,  3],\n",
       "         [ 3,  2,  2,  4,  2,  8,  6],\n",
       "         [ 6,  5,  2,  4,  5,  4,  0],\n",
       "         [ 4,  6,  4,  2,  0,  1,  2],\n",
       "         [ 1,  2,  6,  1, 11,  3,  3],\n",
       "         [10,  7,  0,  4, 10,  4, 10],\n",
       "         [ 4,  5,  7,  5,  6, 10,  8],\n",
       "         [ 6,  5,  5,  4,  5,  5, 10],\n",
       "         [ 1,  2,  1,  4, 11,  2,  3],\n",
       "         [11,  9,  5, 10,  9, 10,  8],\n",
       "         [ 9, 11, 10, 11, 11, 10,  5],\n",
       "         [ 5,  9,  7,  1,  6,  9, 10],\n",
       "         [ 7,  5,  5,  6, 11, 10, 11],\n",
       "         [11,  9, 11, 11, 11,  3,  0],\n",
       "         [ 2,  5,  0,  1,  1,  1,  2],\n",
       "         [ 2, 10,  3,  2,  0,  1,  1],\n",
       "         [ 3,  2,  3,  4,  1,  2,  1],\n",
       "         [ 5,  4,  5,  3,  4, 11,  4],\n",
       "         [11,  4,  6,  9,  5,  5,  9],\n",
       "         [11,  9,  8, 10,  8,  9, 10],\n",
       "         [ 8,  9,  3,  1,  1,  0,  9],\n",
       "         [ 6,  5,  5,  3,  4,  5,  6],\n",
       "         [11,  9, 10, 11,  9, 11,  6],\n",
       "         [ 3,  8,  2, 11,  4,  8, 10],\n",
       "         [ 0,  2,  3,  5,  1,  1,  6],\n",
       "         [ 5,  9,  4,  7,  7,  4,  7],\n",
       "         [10,  0,  0,  9,  3,  1,  2],\n",
       "         [ 3, 11, 10,  4,  4,  5,  4],\n",
       "         [ 8,  8, 11,  8,  8,  4,  8],\n",
       "         [ 9, 10, 11, 10,  8,  9,  0],\n",
       "         [ 1,  3,  1, 10,  0,  1,  0],\n",
       "         [ 4,  7,  2,  2,  0,  8, 11],\n",
       "         [ 4,  6,  5,  4,  4, 11,  9],\n",
       "         [11,  5,  9,  8, 10,  9,  5],\n",
       "         [ 1,  1,  3,  0,  2, 11,  1],\n",
       "         [ 1,  0,  3,  0,  0,  0,  3],\n",
       "         [ 0,  4,  4,  5,  7,  4, 11],\n",
       "         [ 4,  1,  2,  1,  1,  0,  9],\n",
       "         [ 6, 10, 11,  9,  7, 11,  5],\n",
       "         [ 5,  4,  5,  6,  7,  4,  8],\n",
       "         [ 2,  5,  4,  9,  7,  5,  2],\n",
       "         [11,  8,  9,  3, 11, 11, 11],\n",
       "         [ 5,  1,  3,  4,  3,  1,  0],\n",
       "         [ 1,  1,  3,  0,  1,  2,  3],\n",
       "         [ 1,  3,  5,  4,  4,  5,  4],\n",
       "         [ 9, 11,  9,  7, 10,  7,  5],\n",
       "         [ 7,  7,  0,  3,  7,  5,  4],\n",
       "         [10,  9,  8, 11, 10,  0, 11]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb1b63b-2431-4b9e-b170-8b01ae59b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transformer_kwargs(cfg):\n",
    "    model_cfg = cfg[\"sweep_config\"][\"model_config\"]\n",
    "    pure_model = cfg[\"model_config\"]\n",
    "    return {\n",
    "        \"n_layers\": model_cfg[\"n_layers\"][0],\n",
    "        \"n_heads\": model_cfg[\"n_heads\"][0],\n",
    "        \"d_head\":  model_cfg[\"d_head\"][0],\n",
    "        \"d_model\": model_cfg[\"d_head\"][0] * model_cfg[\"n_heads\"][0],\n",
    "        \"d_mlp\":  4 * (model_cfg[\"d_head\"][0] * model_cfg[\"n_heads\"][0]),\n",
    "        \"act_fn\": pure_model[\"act_fn\"],\n",
    "        \"normalization_type\": pure_model[\"normalization_type\"],\n",
    "        \"attn_only\": pure_model[\"attn_only\"],\n",
    "        \"seed\": pure_model[\"seed\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13cbfd27-1ee9-4d23-b861-2cff7065332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import yaml, torch\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "cfg_path = \"/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/configs/experiment_config_transformer_mess3_bloch_hw.yaml\"\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "X1, Y1 = next(iter(train_loader))\n",
    "\n",
    "model = HookedTransformer(\n",
    "    HookedTransformerConfig(\n",
    "        n_ctx=X1.shape[1], \n",
    "        d_vocab=int(torch.stack([X1.max(), Y1.max()]).max().item()) + 1,\n",
    "        device=device,\n",
    "        dtype=getattr(torch, cfg[\"model_config\"][\"dtype\"]),\n",
    "        **extract_transformer_kwargs(cfg)\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f593743-dfb0-4471-8528-492ba943a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "batch_sizes = (128, 256)\n",
    "amplifiers = (20, 12)\n",
    "\n",
    "\n",
    "loader_kwargs = dict(\n",
    "    num_workers=max(4, os.cpu_count()//2),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_sizes[0]*amplifiers[0],           \n",
    "    shuffle=True,\n",
    "    **loader_kwargs\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_sizes[1]*amplifiers[1],\n",
    "    shuffle=False,\n",
    "    **loader_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea663500-6afc-4c0c-9f3d-18de4a87553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"sweep_config\"][\"train_config\"][\"learning_rate\"][0]*amplifiers[0])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=10, threshold=1e-6\n",
    ")\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_loss_ce():\n",
    "    model.eval()\n",
    "    tot, denom = 0.0, 0\n",
    "    for X, Y in val_loader:\n",
    "        X, Y = X.to(device), Y.to(device).long()\n",
    "        logits = model(X)  # [B, L, V]\n",
    "        B, L, V = logits.shape\n",
    "        loss = F.cross_entropy(logits.reshape(-1, V), Y.reshape(-1), reduction=\"sum\")\n",
    "        tot += loss.item(); denom += B*L\n",
    "    return tot / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd4c79c-b45b-40c4-b637-8531905acc64",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%| | 861/20000 [04:52<1:48:28,  2.94it/s, lr=1.22e-08, train_loss=2.1724, val_loss=2.2464]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m X, Y = X.to(device), Y.to(device).long()\n\u001b[32m     13\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m B, L, V = logits.shape\n\u001b[32m     16\u001b[39m loss = F.cross_entropy(logits.reshape(-\u001b[32m1\u001b[39m, V), Y.reshape(-\u001b[32m1\u001b[39m), reduction=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:612\u001b[39m, in \u001b[36mHookedTransformer.forward\u001b[39m\u001b[34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    608\u001b[39m         shortformer_pos_embed = shortformer_pos_embed.to(\n\u001b[32m    609\u001b[39m             devices.get_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    610\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     residual = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    622\u001b[39m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/transformer_lens/components/transformer_block.py:165\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[39m\n\u001b[32m    153\u001b[39m     key_input = attn_in\n\u001b[32m    154\u001b[39m     value_input = attn_in\n\u001b[32m    156\u001b[39m attn_out = (\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28mself\u001b[39m.attn(\n\u001b[32m    161\u001b[39m         query_input=\u001b[38;5;28mself\u001b[39m.ln1(query_input)\n\u001b[32m    162\u001b[39m         + (\u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[32m    163\u001b[39m         key_input=\u001b[38;5;28mself\u001b[39m.ln1(key_input)\n\u001b[32m    164\u001b[39m         + (\u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         value_input=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m(value_input),\n\u001b[32m    166\u001b[39m         past_kv_cache_entry=past_kv_cache_entry,\n\u001b[32m    167\u001b[39m         attention_mask=attention_mask,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_normalization_before_and_after:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[32m    174\u001b[39m     attn_out = \u001b[38;5;28mself\u001b[39m.ln1_post(attn_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1927\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1922\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1926\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1928\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1929\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "EPOCHS = cfg[\"train_config\"][\"n_epochs\"]\n",
    "best = float(\"inf\")\n",
    "pbar = tqdm(range(EPOCHS), desc=\"train\")\n",
    "WARMUP_STEPS = 1000\n",
    "global_step = 0\n",
    "for g in optimizer.param_groups: g['lr'] = 0\n",
    "\n",
    "\n",
    "for ep in pbar:\n",
    "    model.train()\n",
    "    running_loss, steps = 0.0, 0\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device).long()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(X)\n",
    "        B, L, V = logits.shape\n",
    "        loss = F.cross_entropy(logits.reshape(-1, V), Y.reshape(-1), reduction=\"mean\")\n",
    "        loss.backward(); optimizer.step()\n",
    "        running_loss += loss.item(); steps += 1\n",
    "\n",
    "    train_loss = running_loss / max(steps, 1)\n",
    "    v = val_loss_ce()\n",
    "    scheduler.step(v)\n",
    "\n",
    "    if v < best:\n",
    "        best = v\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "    pbar.set_postfix(train_loss=f\"{train_loss:.4f}\", val_loss=f\"{v:.4f}\", lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3da66ba-b69d-4a85-9645-a1e768df4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "batch_sizes = (128, 256)\n",
    "amplifiers = (20, 12)\n",
    "\n",
    "\n",
    "loader_kwargs = dict(\n",
    "    num_workers=max(4, os.cpu_count()//2),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_sizes[0]*amplifiers[0],           \n",
    "    shuffle=True,\n",
    "    **loader_kwargs\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_sizes[1]*amplifiers[1],\n",
    "    shuffle=False,\n",
    "    **loader_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1495316-ce76-4ef7-a9fa-c225b5263faa",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0438056-5935-4344-bf7b-fd98760f0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace-SR008.nfs2/nachevsky/simplex/epsilon-transformers/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "from epsilon_transformers.training.generate_data import (\n",
    "    load_config,\n",
    "    generate_and_save_data,\n",
    "    load_process_data,   \n",
    "    get_process_string, \n",
    ")\n",
    "from extractors import extract_transformer_kwargs, get_caches\n",
    "from tokenizer import TokenizerMessBloch\n",
    "\n",
    "\n",
    "loader_kwargs = dict(\n",
    "    num_workers=max(24, os.cpu_count()),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=40,\n",
    ")\n",
    "\n",
    "\n",
    "def get_dataloaders(dataset, batch_sizes=(128, 256), amplifiers=(20, 12), split_ratio=0.9):\n",
    "    split_idx = int(len(dataset) * split_ratio)\n",
    "    train_idx, val_idx = dataset[:split_idx], dataset[split_idx:]\n",
    "\n",
    "    train_ds = TensorDataset(train_idx[:, :-1], train_idx[:, 1:])\n",
    "    val_ds = TensorDataset(val_idx[:, :-1], val_idx[:, 1:])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_sizes[0]*amplifiers[0],           \n",
    "        shuffle=True,\n",
    "        **loader_kwargs\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_sizes[1]*amplifiers[1],\n",
    "        shuffle=False,\n",
    "        **loader_kwargs\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def get_dataset_from_caches(cfg):\n",
    "    bloch_cache, mess3_cache = get_caches(cfg)\n",
    "    X_bloch_all = torch.tensor(bloch_cache[\"transformer_inputs\"], dtype=torch.long)\n",
    "    X_mess3_all = torch.tensor(mess3_cache[\"transformer_inputs\"], dtype=torch.long)\n",
    "    steps = int(X_bloch_all.shape[0] / X_mess3_all.shape[0])\n",
    "    X_mess3_all_new = torch.concat([X_mess3_all for _ in range(steps+1)])[:X_bloch_all.shape[0]]\n",
    "    tokenizer = TokenizerMessBloch()\n",
    "    return tokenizer.encode(X_mess3_all_new, X_bloch_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5729aa8c-2943-424d-b5d5-4de55c773201",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_loss_ce(model, val_loader):\n",
    "    model.eval()\n",
    "    tot, denom = 0.0, 0\n",
    "    for X, Y in val_loader:\n",
    "        X, Y = X.to(device), Y.to(device).long()\n",
    "        logits = model(X)  # [B, L, V]\n",
    "        B, L, V = logits.shape\n",
    "        loss = F.cross_entropy(logits.reshape(-1, V), Y.reshape(-1), reduction=\"sum\")\n",
    "        tot += loss.item(); denom += B*L\n",
    "    return tot / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a0e17f-d2f8-4595-88f6-b1038a320835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "amplifiers = (20, 12)\n",
    "CFG_PATH = \"configs/experiment_config_transformer_mess3_bloch_hw.yaml\"\n",
    "cfg = load_config(CFG_PATH)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = get_dataset_from_caches(cfg)\n",
    "\n",
    "model = HookedTransformer(\n",
    "    HookedTransformerConfig(\n",
    "        n_ctx=cfg[\"model_config\"][\"n_ctx\"]+1, \n",
    "        d_vocab=12,\n",
    "        device=device,\n",
    "        dtype=getattr(torch, cfg[\"model_config\"][\"dtype\"]),\n",
    "        **extract_transformer_kwargs(cfg)\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9a244-15a4-4152-a727-685f5c9cbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = float(\"inf\")\n",
    "pbar = tqdm(range(cfg[\"train_config\"][\"n_epochs\"]), desc=\"train\")\n",
    "WARMUP_STEPS = 30\n",
    "global_step = 0\n",
    "\n",
    "\n",
    "amplifiers = (200, 300)\n",
    "train_loader, val_loader = get_dataloaders(dataset, amplifiers=amplifiers)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=cfg[\"sweep_config\"][\"train_config\"][\"learning_rate\"][0]*amplifiers[0]\n",
    "    )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=10, threshold=1e-6\n",
    ")\n",
    "\n",
    "base_lr = optimizer.param_groups[0]['lr'] \n",
    "for g in optimizer.param_groups: g['lr'] = 0\n",
    "\n",
    "\n",
    "for ep in pbar:\n",
    "    model.train()\n",
    "    running_loss, steps = 0.0, 0\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device).long()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(X)\n",
    "        B, L, V = logits.shape\n",
    "        loss = F.cross_entropy(logits.reshape(-1, V), Y.reshape(-1), reduction=\"mean\")\n",
    "        loss.backward(); optimizer.step()\n",
    "        running_loss += loss.item(); steps += 1\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step <= WARMUP_STEPS:\n",
    "            wlr = base_lr * (global_step / WARMUP_STEPS)\n",
    "            for g in optimizer.param_groups: g['lr'] = wlr    \n",
    "    \n",
    "    train_loss = running_loss / max(steps, 1)\n",
    "    val_loss = val_loss_ce(model, val_loader)\n",
    "    if global_step > WARMUP_STEPS:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # if val_loss < best:\n",
    "    #     best = val_loss\n",
    "    #     torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "    pbar.set_postfix(train_loss=f\"{train_loss:.4f}\", val_loss=f\"{val_loss:.4f}\", lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e35152-9633-41ae-b14a-14d84a459cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "\n",
    "amplifiers = (1, 1)\n",
    "train_loader, val_loader = get_dataloaders(dataset, amplifiers=amplifiers)\n",
    "base_lr = cfg[\"sweep_config\"][\"train_config\"][\"learning_rate\"][0]*amplifiers[0]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=base_lr,\n",
    "    fused=True if torch.cuda.is_available() else False,  # ускоряет шаг оптимизации\n",
    "    betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01\n",
    ")\n",
    "\n",
    "scaler = GradScaler(enabled=True)\n",
    "grad_accum_steps = 4\n",
    "\n",
    "\n",
    "WARMUP_STEPS = 30\n",
    "def lr_lambda(step):\n",
    "    if step < WARMUP_STEPS:\n",
    "        return float(step + 1) / float(WARMUP_STEPS)   # линейный warmup 0→1\n",
    "    return 1.0\n",
    "\n",
    "warmup = LambdaLR(optimizer, lr_lambda)\n",
    "plateau = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=10, threshold=1e-6)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(cfg[\"train_config\"][\"n_epochs\"]), desc=\"train\")\n",
    "best = float(\"inf\")\n",
    "global_step = 0\n",
    "\n",
    "for ep in pbar:\n",
    "    model.train()\n",
    "    running_loss, steps = 0.0, 0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for it, (X, Y) in enumerate(train_loader):\n",
    "        # важны non_blocking + pin_memory=True в DataLoader\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        Y = Y.to(device, non_blocking=True).long()\n",
    "\n",
    "        with autocast(dtype=torch.bfloat16, enabled=True):  # или torch.float16 при поддержке\n",
    "            logits = model(X)  # ожидается (B, L, V)\n",
    "            B, L, V = logits.shape\n",
    "            loss = F.cross_entropy(logits.reshape(-1, V), Y.reshape(-1), reduction=\"mean\")\n",
    "\n",
    "        scaler.scale(loss / grad_accum_steps).backward()\n",
    "\n",
    "        if (it + 1) % grad_accum_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            global_step += 1\n",
    "            warmup.step()  # применяем warmup на каждый \"оптимизационный\" шаг\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        steps += 1\n",
    "\n",
    "    train_loss = running_loss / max(steps, 1)\n",
    "\n",
    "    # === Валидация без градиентов и без autocast (или с autocast для скорости) ===\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = val_loss_ce(model, val_loader)  # убедись, что внутри нет .item() в цикле\n",
    "\n",
    "    # После warmup — Plateau по вал-лоссу\n",
    "    if global_step >= WARMUP_STEPS:\n",
    "        plateau.step(val_loss)\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        train_loss=f\"{train_loss:.4f}\",\n",
    "        val_loss=f\"{val_loss:.4f}\",\n",
    "        lr=f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c633eb-4991-4c01-a4f9-5b2e45a95734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simplex",
   "language": "python",
   "name": "epsilon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
